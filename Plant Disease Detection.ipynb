{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 1- Uplaoding necessary libraries "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-05T21:56:53.754944Z","iopub.status.busy":"2022-12-05T21:56:53.754485Z","iopub.status.idle":"2022-12-05T21:57:00.630198Z","shell.execute_reply":"2022-12-05T21:57:00.629048Z","shell.execute_reply.started":"2022-12-05T21:56:53.754863Z"},"id":"HWdt2AH5_tht","trusted":true},"outputs":[],"source":["import os\n","import pickle\n","import zipfile\n","import random\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.optimizers import RMSprop\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from shutil import copyfile\n","import numpy as np\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import (\n","    BatchNormalization, Conv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense\n",")\n","from tensorflow.keras import backend as K\n","from sklearn.preprocessing import LabelBinarizer\n","from keras.preprocessing import image\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{},"source":["# 3- Creating Distiller Class "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-05T21:57:10.107668Z","iopub.status.busy":"2022-12-05T21:57:10.107112Z","iopub.status.idle":"2022-12-05T21:57:10.12193Z","shell.execute_reply":"2022-12-05T21:57:10.120932Z","shell.execute_reply.started":"2022-12-05T21:57:10.107634Z"},"id":"kFQyytXV_thv","trusted":true},"outputs":[],"source":["class Distiller(keras.Model):\n","    def __init__(self, student, teacher):\n","        super(Distiller, self).__init__()\n","        self.teacher = teacher\n","        self.student = student\n","\n","    def compile(\n","        self,\n","        optimizer,\n","        metrics,\n","        student_loss_fn,\n","        distillation_loss_fn,\n","        alpha=0.1,\n","        temperature=3,\n","    ):\n","        \"\"\" Configure the distiller.\n","\n","        Args:\n","            optimizer: Keras optimizer for the student weights\n","            metrics: Keras metrics for evaluation\n","            student_loss_fn: Loss function of difference between student\n","                predictions and ground-truth\n","            distillation_loss_fn: Loss function of difference between soft\n","                student predictions and soft teacher predictions\n","            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n","            temperature: Temperature for softening probability distributions.\n","                Larger temperature gives softer distributions.\n","        \"\"\"\n","        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n","        self.student_loss_fn = student_loss_fn\n","        self.distillation_loss_fn = distillation_loss_fn\n","        self.alpha = alpha\n","        self.temperature = temperature\n","\n","    def train_step(self, data):\n","        # Unpack data\n","        x, y = data\n","\n","        # Forward pass of teacher\n","        teacher_predictions = self.teacher(x, training=False)\n","\n","        with tf.GradientTape() as tape:\n","            # Forward pass of student\n","            student_predictions = self.student(x, training=True)\n","\n","            # Compute losses\n","            student_loss = self.student_loss_fn(y, student_predictions)\n","            distillation_loss = self.distillation_loss_fn(\n","                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n","                tf.nn.softmax(student_predictions / self.temperature, axis=1),\n","            )\n","            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n","\n","        # Compute gradients\n","        trainable_vars = self.student.trainable_variables\n","        gradients = tape.gradient(loss, trainable_vars)\n","\n","        # Update weights\n","        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n","\n","        # Update the metrics configured in `compile()`.\n","        self.compiled_metrics.update_state(y, student_predictions)\n","\n","        # Return a dict of performance\n","        results = {m.name: m.result() for m in self.metrics}\n","        results.update(\n","            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n","        )\n","        return results\n","\n","    def test_step(self, data):\n","        # Unpack the data\n","        x, y = data\n","\n","        # Compute predictions\n","        y_prediction = self.student(x, training=False)\n","\n","        # Calculate the loss\n","        student_loss = self.student_loss_fn(y, y_prediction)\n","\n","        # Update the metrics.\n","        self.compiled_metrics.update_state(y, y_prediction)\n","        # Return a dict of performance\n","        results = {m.name: m.result() for m in self.metrics}\n","        results.update({\"student_loss\": student_loss})\n","        return results\n","    def call(self, data, training=False): \n","        # You don't need this method for training.\n","        # So just pass.\n","        pass\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-05T21:57:20.924171Z","iopub.status.busy":"2022-12-05T21:57:20.923785Z","iopub.status.idle":"2022-12-05T22:04:50.02535Z","shell.execute_reply":"2022-12-05T22:04:50.024163Z","shell.execute_reply.started":"2022-12-05T21:57:20.924138Z"},"id":"qhfoipB-Igep","trusted":true},"outputs":[],"source":["!pip install split-folders\n","import splitfolders\n","splitfolders.ratio('../input/plantvillage-dataset/color', output=\"output\", seed=1337, ratio=(.8, 0.1,0.1))"]},{"cell_type":"markdown","metadata":{},"source":["# 4- Flowing Images from directory\n","In step 4, the traning and validation datasets are flown from the directory to a variables called train_generator and validation_genearator. we also specify the batch size and resize all the images to 250 by 250px."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-05T22:08:44.116293Z","iopub.status.busy":"2022-12-05T22:08:44.115186Z","iopub.status.idle":"2022-12-05T22:08:46.604897Z","shell.execute_reply":"2022-12-05T22:08:46.603876Z","shell.execute_reply.started":"2022-12-05T22:08:44.116217Z"},"id":"JOoCrrVqStdP","outputId":"99c7f1fd-4bbd-4e53-f1d5-95e53e608738","trusted":true},"outputs":[],"source":["TRAINING_DIR = \"./output/train\"\n","train_datagen = ImageDataGenerator(rescale=1.0/255\n","                \n","               )\n","train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n","                                                    class_mode='categorical',\n","                                                    batch_size=250,\n","                                                    target_size=(250, 250))\n","\n","VALIDATION_DIR = \"./output/test\"\n","validation_datagen = ImageDataGenerator(rescale=1.0/255.)\n","validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n","                                                              class_mode='categorical',\n","                                                              batch_size=250,\n","                                                              target_size=(250, 250))"]},{"cell_type":"markdown","metadata":{},"source":["# Sample Images From the Dataset\n","The code below defines a method plotImages which defined how to  plot sample images from the dataset using matplotlib library and imshow() method.  The Imagedatagenerator output array train_generator was used as input array to the method and then  five images  were selected from it."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-19T00:44:49.645445Z","iopub.status.busy":"2022-10-19T00:44:49.645077Z","iopub.status.idle":"2022-10-19T00:44:52.685527Z","shell.execute_reply":"2022-10-19T00:44:52.684646Z","shell.execute_reply.started":"2022-10-19T00:44:49.645415Z"},"trusted":true},"outputs":[],"source":["def plotImages(images_arr):\n","    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n","    axes = axes.flatten()\n","    for img, ax in zip( images_arr, axes):\n","        ax.imshow(img)\n","    plt.tight_layout()\n","    plt.show()\n","    \n","    \n","augmented_images = [train_generator[0][0][0] for i in range(5)]\n","plotImages(augmented_images)"]},{"cell_type":"markdown","metadata":{},"source":["# 5- Getting Categorical Labels\n","We obtained the the labels associated with each images that is all the directories name from our dataset and assign it to a varaible called train_y "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-18T23:22:46.545781Z","iopub.status.busy":"2022-10-18T23:22:46.545002Z","iopub.status.idle":"2022-10-18T23:22:46.551033Z","shell.execute_reply":"2022-10-18T23:22:46.549665Z","shell.execute_reply.started":"2022-10-18T23:22:46.545745Z"},"id":"pbPmmxL9ImdX","trusted":true},"outputs":[],"source":["train_y=train_generator.classes\n"]},{"cell_type":"markdown","metadata":{},"source":["# 6- Converting categorical labels to binary otherwise called (Encoding)\n","Label Binarizer is an SciKit Learn class that accepts Categorical data as input and returns an Numpy array. Unlike Label Encoder, it encodes the data into dummy variables indicating the presence of a particular label or not. Encoding make column data using Label Binarizer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-18T23:22:56.344538Z","iopub.status.busy":"2022-10-18T23:22:56.343962Z","iopub.status.idle":"2022-10-18T23:22:56.364203Z","shell.execute_reply":"2022-10-18T23:22:56.363288Z","shell.execute_reply.started":"2022-10-18T23:22:56.344503Z"},"id":"0wgaFsbXB7Wz","trusted":true},"outputs":[],"source":["label_binarizer = LabelBinarizer()\n","image_labels = label_binarizer.fit_transform(train_y)\n","pickle.dump(label_binarizer,open('label_transform.pkl', 'wb'))\n","n_classes = len(label_binarizer.classes_)"]},{"cell_type":"markdown","metadata":{"id":"0FEs8I3n_thy"},"source":["## 7- Create student and teacher models\n","\n","Initialy, we create a teacher model and a smaller student model using keras. Both models are\n","convolutional neural networks and created using `Sequential()`,\n","but could be any Keras model."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-18T23:23:32.707337Z","iopub.status.busy":"2022-10-18T23:23:32.706795Z","iopub.status.idle":"2022-10-18T23:23:36.006772Z","shell.execute_reply":"2022-10-18T23:23:36.005867Z","shell.execute_reply.started":"2022-10-18T23:23:32.707289Z"},"id":"3QxuJlS7_thz","trusted":true},"outputs":[],"source":["# Create the teacher\n","teacher = keras.Sequential(name=\"teacher\",)\n","inputShape = (250, 250, 3)\n","chanDim = -1\n","if K.image_data_format() == \"channels_first\":\n","           inputShape = (3, 250, 250)\n","           chanDim = 1\n","teacher.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\n","teacher.add(Activation(\"relu\"))\n","teacher.add(BatchNormalization(axis=chanDim))\n","teacher.add(MaxPooling2D(pool_size=(3, 3)))\n","teacher.add(Dropout(0.25))\n","teacher.add(Conv2D(64, (3, 3), padding=\"same\"))\n","teacher.add(Activation(\"relu\"))\n","teacher.add(BatchNormalization(axis=chanDim))\n","teacher.add(Conv2D(64, (3, 3), padding=\"same\"))\n","teacher.add(Activation(\"relu\"))\n","teacher.add(BatchNormalization(axis=chanDim))\n","teacher.add(MaxPooling2D(pool_size=(2, 2)))\n","teacher.add(Dropout(0.25))\n","teacher.add(Conv2D(128, (3, 3), padding=\"same\"))\n","teacher.add(Activation(\"relu\"))\n","teacher.add(BatchNormalization(axis=chanDim))\n","teacher.add(Conv2D(128, (3, 3), padding=\"same\"))\n","teacher.add(Activation(\"relu\"))\n","teacher.add(BatchNormalization(axis=chanDim))\n","teacher.add(MaxPooling2D(pool_size=(2, 2)))\n","teacher.add(Dropout(0.25))\n","teacher.add(Flatten())\n","teacher.add(Dense(1024))\n","teacher.add(Activation(\"relu\"))\n","teacher.add(BatchNormalization())\n","teacher.add(Dropout(0.5))\n","teacher.add(Dense(n_classes))\n","\n","\n","# Create the student\n","student = keras.Sequential(\n","    [\n","        keras.Input(shape=(250, 250, 3)),\n","        layers.Conv2D(16, (3, 3), strides=(2, 2), padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n","        layers.Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\"),\n","        layers.LeakyReLU(alpha=0.2),\n","        layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\"),\n","        layers.Flatten(),\n","        layers.Dense(n_classes),\n","    ],\n","    name=\"student\",\n",")\n","\n","# Clone student for later comparison\n","student_scratch = keras.models.clone_model(student)"]},{"cell_type":"markdown","metadata":{},"source":["# 8- Displaying the model summary\n","the custom method 'summary' allows us to diplay the architecture of the models described above, this allows us to know thw number parameters avaible in our defined model."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-18T23:24:14.326204Z","iopub.status.busy":"2022-10-18T23:24:14.325829Z","iopub.status.idle":"2022-10-18T23:24:14.334149Z","shell.execute_reply":"2022-10-18T23:24:14.333173Z","shell.execute_reply.started":"2022-10-18T23:24:14.326172Z"},"id":"lWoEqv4dy0I8","outputId":"1819c477-0695-486e-f852-4392aa33e67c","trusted":true},"outputs":[],"source":["teacher.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-18T23:24:20.517917Z","iopub.status.busy":"2022-10-18T23:24:20.517Z","iopub.status.idle":"2022-10-18T23:24:20.525605Z","shell.execute_reply":"2022-10-18T23:24:20.524568Z","shell.execute_reply.started":"2022-10-18T23:24:20.517871Z"},"trusted":true},"outputs":[],"source":["student.summary()"]},{"cell_type":"markdown","metadata":{},"source":["# 9- Compiling Teacher Model for training\n","The teacher model is first compile using custom compile method to achieve better accucaracy and learn more information"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-18T23:24:48.513578Z","iopub.status.busy":"2022-10-18T23:24:48.513144Z","iopub.status.idle":"2022-10-18T23:24:48.532423Z","shell.execute_reply":"2022-10-18T23:24:48.531463Z","shell.execute_reply.started":"2022-10-18T23:24:48.513541Z"},"id":"zvLjuwTz_th3","trusted":true},"outputs":[],"source":["# Train teacher as usual\n","teacher.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n","    metrics=['acc'],\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"i1-EZCqg_th2"},"source":["## 10- Train the teacher\n","\n","During training Step, the model sifts through preexisting data and draws conclusions based on what it “thinks” the data represents. Every time it comes to an incorrect conclusion, that result is fed back to the system so that it “learns” from its mistake. \n","\n","This process makes connections between the artificial neurons stronger over time and increases the likelihood that the system will make accurate predictions in the future. As it’s presented with novel data, the DNN should be able to categorize and analyze new and possibly more complex information. Ultimately, it will continue to learn from its encounters and become more intuitive over time.\n","* ** to train a model a fit() method is called on the model, fit takes arguments such as trainig data, validation data, epoch, train step and valudation step.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-18T23:24:56.645068Z","iopub.status.busy":"2022-10-18T23:24:56.644711Z","iopub.status.idle":"2022-10-18T23:39:10.728715Z","shell.execute_reply":"2022-10-18T23:39:10.72774Z","shell.execute_reply.started":"2022-10-18T23:24:56.645037Z"},"id":"3HFaxRxy9FH0","outputId":"25f741e9-0d47-428e-ebac-673f69589451","trusted":true},"outputs":[],"source":["teacher_history=teacher.fit(train_generator, validation_data=validation_generator, epochs=5)\n"]},{"cell_type":"markdown","metadata":{},"source":["**11- Plotting Teacher Model Accuracy and loss Curves**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-18T23:40:42.612256Z","iopub.status.busy":"2022-10-18T23:40:42.611856Z","iopub.status.idle":"2022-10-18T23:40:43.042607Z","shell.execute_reply":"2022-10-18T23:40:43.041731Z","shell.execute_reply.started":"2022-10-18T23:40:42.612224Z"},"id":"rgkyk-XX8nBx","outputId":"8f493266-52fc-42da-a72f-54ef27dc4a35","trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","acc = teacher_history.history['acc']\n","val_acc = teacher_history.history['val_acc']\n","loss = teacher_history.history['loss']\n","val_loss = teacher_history.history['val_loss']\n","print(range(1, len(acc) + 1))\n","\n","epochs = range(1, len(acc) + 1)\n","#Train and validation accuracy\n","plt.plot(epochs, acc, 'b', label='Training accurarcy')\n","plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n","plt.title('Training and Validation accurarcy')\n","plt.legend()\n","\n","\n","\n","plt.figure()\n","#Train and validation loss\n","plt.plot(epochs, loss, 'b', label='Training loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation loss')\n","plt.title('Training and Validation loss')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["**12 Distilling teacher knowledge to student Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-19T00:07:36.649085Z","iopub.status.busy":"2022-10-19T00:07:36.648734Z","iopub.status.idle":"2022-10-19T00:15:33.300406Z","shell.execute_reply":"2022-10-19T00:15:33.299468Z","shell.execute_reply.started":"2022-10-19T00:07:36.649054Z"},"id":"KlGGhzlR_th5","outputId":"4715bbe0-d955-4670-c07f-2bf9f414be25","trusted":true},"outputs":[],"source":["# Initialize and compile distiller\n","distiller = Distiller(student=student, teacher=teacher)\n","distiller.compile(optimizer=keras.optimizers.Adam(), metrics=['acc'],\n","    student_loss_fn=keras.losses.CategoricalCrossentropy(from_logits=True),\n","    distillation_loss_fn=keras.losses.KLDivergence(),alpha=0.1,temperature=10,)\n","\n","# Distill teacher to student\n","student_history=distiller.fit(train_generator, validation_data=validation_generator, epochs=3)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Plotting Student model Accuracy and loss curves\n","to investigate the performance of the student model for comparison with teacher model, an accaucry and validation curve was plotted below."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-19T00:21:03.873323Z","iopub.status.busy":"2022-10-19T00:21:03.87294Z","iopub.status.idle":"2022-10-19T00:21:04.282036Z","shell.execute_reply":"2022-10-19T00:21:04.281025Z","shell.execute_reply.started":"2022-10-19T00:21:03.873289Z"},"id":"HOOKHDiY5WxB","outputId":"989cd02d-922b-4607-b4a8-21bab9a62a05","trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","acc = student_history.history['acc']\n","val_acc =student_history.history['val_acc']\n","loss = student_history.history['distillation_loss']\n","val_loss = student_history.history['student_loss']\n","print(range(1, len(acc) + 1))\n","\n","epochs = range(1, len(acc) + 1)\n","#Train and validation accuracy\n","plt.plot(epochs, acc, 'b', label='Training accurarcy')\n","plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n","plt.title('Training and Validation accurarcy')\n","plt.legend()\n","\n","\n","\n","plt.figure()\n","#Train and validation loss\n","plt.plot(epochs, loss, 'b', label='Training loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation loss')\n","plt.title('Training and Validation loss')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"-yry13lQ_th5"},"source":["## Train student from scratch for comparison\n","\n","We can also train an equivalent student model from scratch without the teacher, in order\n","to evaluate the performance gain obtained by knowledge distillation."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-18T14:25:18.703692Z","iopub.status.busy":"2022-10-18T14:25:18.703277Z","iopub.status.idle":"2022-10-18T14:28:12.615445Z","shell.execute_reply":"2022-10-18T14:28:12.614494Z","shell.execute_reply.started":"2022-10-18T14:25:18.703659Z"},"id":"4cge2ZSR_th5","outputId":"e0c0685e-5040-4be5-a4fd-73e2d30d53d1","trusted":true},"outputs":[],"source":["# Train student as doen usually\n","student_scratch.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n","    metrics=['acc'],\n",")\n","\n","# Train and evaluate student trained from scratch.\n","student_scratch.fit(train_generator, epochs=1)\n","std_history=student_scratch.evaluate(validation_generator)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
